TRANSLATION LOOK-ASIDE BUFFER

To speed up paging, we use the translation look-aside buffer (TLB).
It's part of the MMU and is a cache of popular virtual-to-physical address translations.

Before consulting page table, hardware sees if it can resolve a memory reference with the TLB.
If the VPN matches, we have a TLB hit, and don't need to consult the page table.
If we have a TLB miss, we consult the page table, then update the TLB with our new translation.

spatial locality - stuff close in array yield hits
temporal locality - revisit stuff we visited before yields hits

Before the hardware would handle the misses, looking up the page table on its own.
Today, the OS handles it. A miss initiates a trap, and a trap handler does page table stuff.

Before, a return from trap would resume after the instruction that caused the trap.
Now, we resume at the instruction that caused the trap, let it run again, and cause a TLB hit.

Make sure you don't get infinite chains of misses.
Save some permanent slots in TLB for miss handling code.
wired translations always hit.

Using software to control TLB is flexible; can use any data structure. Also simpler.

If a TLB is "fully associative", then any translation can be anywhere in the TLB.
Such a TLB would contain both VPN and PPN because it is fully associative.

TLB entry also has a "valid bit" which says if translation is valid.
Also has protection bits (rwx), address space identifier, and dirty bit.

The translations in a TLB are useless to other processes.
One solution is to "flush" TLB between context switches. However, this means there will be misses when we switch back.
Thus an address space identifier will alow sharing of TLB's and identify translations w a certain process.

When you make a new cache in TLB, you're replacing an old one.
Sometimes, we evict the "least recently used" entry.
Or it evicts at random, especially for corner case behaviors, like loop over n+1 pages w a TLB of size n (LRU fails in this case)