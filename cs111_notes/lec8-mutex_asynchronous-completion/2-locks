LOCKS

lock_t mutex;
lock(&mutex);
//critical section
unlock(&mutex);

The POSIX library calls its lock a mutex.
pthread_mutex_t lock;
pthread_mutex_lock(&lock);
//critical section
pthread_mutex_unlock(&lock);

coarse-grained strategy - one lock for all critical sections
fine-grained strategy - different locks for different critical sections

Evaluating a Lock
	Does it provide mutual exclusion?
	Is it fair (no thread starves)?
	What is the overhead/performance?

Interrupt Disables
	Earliest form of lock.
	Lock would disable interrupts.
	Unlock would enable interrupts.

	Simple.
	But we're giving each thread priveleged operations. The thread can take control of the processor and the OS can't do anything about it.
	Also doesn't work on multiple processors. You disable interrupts on one processor, the threads will work on other processors.
	Interrupts can be lost.
	Pausing everything slows down throughput.

Load/Store
	Why can't we just use a simple variable as a flag that goes between 0 and 1?
	Threads could access the variable at the same time, and thus access the critical section at the same time, which is bad.
	Such also involves other threads spin-waiting in loops that are wasteful.

test-and-set

	int TestAndSet (int *old_ptr, int new){
		int old = *old_ptr;
		*old_ptr = new;
		return old;
	}

	test-and-set instruction/atomic exchange is used to make a spin-lock.
	We test the old lock while setting it to the new one, and do it all atomically.
	Simplest type of lock, involves other threads spin-waiting, and a pre-emptive scheduler switching threads.

	Correct.
	But not fair. We can't guarantee every waiting thread can get in.
	Pretty bad performance on a single processor. When a thread is in a critical section, the others all have to spin for a time slice, a waste of CPU cycles.
	Performance is better if #threads = #processors, so that other threads can spin on other processors and not waste time.

compare-and-swap
	int CompareAndSwap (int *ptr, int expected, int new){
		int actual = *ptr;
		if(actual == expected)
			*ptr = new;
		return actual;
	}

	while(CompareAndSwap(flag, 0, 1) == 1)
		; //spin

	We update our pointer only if it equals an expected value.
	Can make an identical spin lock as test-and-set.
	Could be used for lock-free synchronization.

load-linked and store-conditional
	int LoadLinked(int *ptr){
		return *ptr;
	}

	int StoreConditional(int *ptr, int value){
		if(*ptr has not been updated since LoadLinked){}
			*ptr = value;
			return 1; //success
		} else {
			return 0;
		}
	}

	while(1){
		while(LoadLinked(flag) == 1)
			;
		if(StoreConditional(flag, 1) == 1)
			return;
	}

	Works like load/store, but has a conditional to ensure no mistakes.

fetch-and-add
	int FetchAndAdd (int *ptr){
		int old = *ptr;
		*ptr = old + 1;
		return old;
	}

	This can be used to make a "ticket lock".
	When a thread wishes to acquire the lock, it does an atomic fetch-and-add on the ticket value, which is its "turn".
	When it's turn equals the lock's turn value, the thread can enter the critical section.
	Incrementing the turn again will make the thread leave and let another in.

	So all threads are guaranteed to run, unlike previous paradigms.

Yielding
	Spinning wastes an entire time slice of CPU cycles.
	Instead, the yield() command should be used to just give the CPU to another thread.
	But this can still be costly if you have a lot of threads (but better than spinning).
	There can also be starvation.

Sleeping
	To ensure fairness and no starvation, we should use a queue.
	Threads are put to sleep via park(), and then woken up via unpark() by the thread before them.
	There is a race condition where a thread might park() right when the thread before unparks(), and end up sleeping forever.
	Thus setpark() was created to announce a thread will eventually park--if unpark happens and this thread has not parked, it will go into the critical section without parking.

Two-Phase Lock
	Spinning is allowed in a first phase. If it hasn't acquired the lock after the first phase, it is put into sleep.