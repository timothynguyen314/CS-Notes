LOCK BASED CONCURRENT DATA STRUCTURES

Add locks to data structures to make them "thread safe".
Once a data structure is thread safe, next step is performance.
"Perfect scaling" is when multiple threads run as fast as a single thread.

Concurrent Counters
	Acquire a lock, manipulate the data structure, release the lock.

	"sloppy counter"
		A single logical counter is represented by multiple local physical counters (one per core) and one global counter, each with their own locks.

		A thread updates its own local counter. If there are four threads on four CPUs, it seems to be perfect scaling...
		Periodically, we update the global counter by adding a local counter's value to it and resetting the local counter to zero.

		The rate of local-to-global transfers depends on S (sloppiness), updating whenever the counter reaches S.
		High S means more scalability but more chance of an innacurate count.

Concurrent Linked List
	For now let's just focus on insert.
	Acquire a lock when inserting into the list.
	Must unlock if malloc() fails.
	Can we avoid the malloc case? Yeah, the lookup code doesn't need to be in the critical section.

	hand-over-hand locking (lock coupling)
	instead of a lock for the entire list, a lock for each node
	to traverse, you'd unlock the current and lock the next.
	conceptually makes sense, splitting up the list...but not really faster than a single lock.

Concurrent Queue
	lock for head, queue, and tail
	concurrency of enqueue and dequeue operations
	a dummy node separates the operations.

Concurrent Hash Table
	lock for each hash bucket, not the entire Table
	very scalable, much more than linked lists