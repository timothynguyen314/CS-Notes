SEMAPHORES AND LOCKS FOR SYNCHRONIZATION

Synchronization Options
	Don't share resources.
	Turn off interrupts to prevent concurrency
	Access resources with atomic instructions.
	Use locks, either by spin waiting, or by using primitives to block when resource is locked and wake when free.

Semaphores
	Designed by Dijkstra.
	Consists of an integer counter and a waiting queue.

	Wait decrements counter, and if counter is negative, add process to queue.
	Post increments counter, and if counter is zero, take process from queue.

	Using Semaphores for Exclusion: The initial count of a lock says how many threads are allowed to hold a lock at once.
	Using Semaphores for Notifications: Initialize count to 0. The count is the number of completed processes.
	Counting Semaphores: Count should reflect number of available resources.

Implementing semaphores
	void sem_wait(sem_t *s){
		pthread_mutex_lock(&s->lock);
		while(s->value <= 0)
			pthread_cond_wait(&s->cond, &s->lock);
		s->value--;
		pthread_mutex_unlock(&s->lock);
	}

	void sem_post(sem_t *s){
		pthread_mutex_lock(&s->lock);
		s->value++;
		pthread_cond_signal(&s->cond);
		pthread_mutex_unlock(&s->lock);
	}

Limitations
	They're a bit simple, lacking features.
	Prone to deadlocks and other problems.

Types of locks
	Mutexes
		A Linux/Unix lock for sections of code
		Low overhead, general, typically used by threads of the same process
		Advisory lock
	Locking Objects/Files
		flock is an advisory lock
		lockf can be an enforced lock
		They lock files/objects, which can be used by multiple programs or even machines. Mutexes don't protect that.

		Advisory means the user gets to put the lock if they want.
		Enforced means the file system makes you put the lock.

Performance
	Locking is typically a system call. Overhead of the lock may be higher than time spent in critical section.
	When you don't get a lock, blocking is 1000x more expensive than locking.
	A "bottleneck" is when multiple processes should be running in parallel, but they're held in convoy because they're all waiting on the same resource.
	The longer the critical section, the more likely you get blocking.

Priority Inversion
	Mars Pathfinder Rover problem: Three tasks of priority P1>P2>P3
	P2 doesn't need a lock for a section, but P1 and P3 do.

	P3 would run and acquire the lock.
	P2 would run.
	P1 can't run because P3 still has the lock.
	P1 can't run until P3 finishes.
	P3 can't preempt P2 because it's of lower priority.
	P3 can't run until P2 finishes.

	To fix this, a "watchdog timer" was ut in effect. If P1 doesn't run for a long time, reset the system.
	Another solution is "priority inheritance", giving priority to P3 when it has the lock so it can't be pre-empted.

Locking Problems
	Not much can be done about reducing overhead.
	But what about reducing contention?

	We could eliminate the critical section, maybe with atomic instructions.
	We could eliminate preemption by disabling interrupts, which leads to possible synchronization problems.
	We could reduce the time in the critical section, esp. by allocating memory or doing I/O before getting the lock.
	We could somehow reduce frequency of using the section.
	we could remove requirement for full exclusivity, like with reader/writer locks.
	We could spread requests over more resources--coarse grained is one lock for entire resource, fine grained is many locks for different objects in the resource.